-->Using Tesseract OCR (Python)

from PIL import Image
import pytesseract

# Load the image
image_path = "answer_sheet.jpg"
image = Image.open(image_path)

# Preprocess the image (optional: resize, grayscale, etc.)
image = image.convert('L')  # Convert to grayscale

# Extract text using Tesseract OCR
extracted_text = pytesseract.image_to_string(image)

print("Extracted Text:")
print(extracted_text)

---------

-->Using Google Vision API (Python)

from google.cloud import vision
import io

# Initialize the Google Vision client
client = vision.ImageAnnotatorClient()

# Load the image
image_path = "answer_sheet.jpg"
with io.open(image_path, 'rb') as image_file:
    content = image_file.read()

image = vision.Image(content=content)

# Perform text detection
response = client.text_detection(image=image)
texts = response.text_annotations

print("Extracted Text:")
for text in texts:
    print(text.description)

-----------

-->NLP Module

import spacy

# Load the spaCy model
nlp = spacy.load("en_core_web_sm")

# Example extracted text from OCR
extracted_text = "Machine learning is a subset of artificial intelligence."

# Process the text with spaCy
doc = nlp(extracted_text)

# Analyze grammar and semantics
print("Tokens and POS Tags:")
for token in doc:
    print(f"Token: {token.text}, POS: {token.pos_}")

# Check for grammatical errors (basic example)
if any(token.pos_ == "PUNCT" for token in doc):
    print("Potential grammatical error: Check punctuation.")

--------

-->Using Hugging Face Transformers for Relevance and Semantic Similarity

from transformers import pipeline

# Load a pre-trained model for text similarity
similarity_pipeline = pipeline("text-classification", model="distilbert-base-uncased")

# Example model answer and student answer
model_answer = "Machine learning is a subset of artificial intelligence."
student_answer = "AI includes machine learning as a part of it."

# Compare the answers for relevance
similarity_score = similarity_pipeline(model_answer, student_answer)
print(f"Similarity Score: {similarity_score}")

-----------

-->Feedback Engine

def generate_feedback(grammar_score, relevance_score, completeness_score):
    feedback = []

    if grammar_score < 0.8:
        feedback.append("Improve grammar and sentence structure.")
    if relevance_score < 0.7:
        feedback.append("Ensure your answer is relevant to the question.")
    if completeness_score < 0.9:
        feedback.append("Provide more details or examples to support your answer.")

    if not feedback:
        feedback.append("Great job! Your answer is well-written and relevant.")

    return feedback

# Example scores
grammar_score = 0.75
relevance_score = 0.65
completeness_score = 0.85

# Generate feedback
feedback = generate_feedback(grammar_score, relevance_score, completeness_score)
print("Feedback:")
for suggestion in feedback:
    print(f"- {suggestion}")

---------


--->Chatbot Module

import openai

# Set up OpenAI API key
openai.api_key = "your_openai_api_key"

# Function to interact with GPT-4
def chatbot_response(user_query):
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a helpful assistant that provides feedback on student answers."},
            {"role": "user", "content": user_query}
        ]
    )
    return response['choices'][0]['message']['content']

# Example user query
user_query = "How can I improve my answer on machine learning?"
response = chatbot_response(user_query)
print("Chatbot Response:")
print(response)


-----------


--->